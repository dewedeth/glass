// THIS FILE WAS GENERATED BY GLASS -- DO NOT EDIT!

import { runGlass } from '@glass-lang/glasslib'

export async function getPyForPrompt(opt: {
  args: { messages: string, True: string },
  options?: {
    openaiKey?: string,
    progress?: (data: { nextDoc: string, rawResponse?: string }) => void,
  },
}) {
  const { messages, True } = opt.args
  messages = [
    { role: 'user', content: 'name an ice cream', show: True },
    { role: 'assistant', content: 'Vanilla', show: True },
    { role: 'user', content: 'name a fruit', show: True },
  ]
  const GLASSVAR = {
    0: m.get('show')
      ? `<Text if={m.get("show")}>
${m.get('content')}
</Text>`
      : '',
    1: messages
      .map(
        (m) => `<Block role={${JSON.stringify(m.get('role'))}}>
<Text if={${JSON.stringify(m.get('show'))}}>
${m.get('content')}
</Text>
</Block>`
      )
      .join('\n\n'),
  }
  const TEMPLATE = `<Code>
messages = [
    { "role": 'user', "content": 'name an ice cream', "show": True  },
    { "role": "assistant", "content": 'Vanilla', "show": True },
    { "role": 'user', "content": 'name a fruit', "show": True  }
]
</Code>

${GLASSVAR[1]}`
  return await runGlass('py-for.glass', 'gpt-3.5-turbo', TEMPLATE, opt.options)
}

export const Glass = {
  pyForGlass: getPyForPrompt,
}

context.response = getPyForPrompt({ args: {}, options: { openaiKey: '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', progress } })