// THIS FILE WAS GENERATED BY GLASS -- DO NOT EDIT!

import { runGlass, useState } from '@glass-lang/glasslib'

import fs from 'fs'
import path from 'path'
import { vectorSearch } from './documentQA/vectorSearch'

export function getXcMqRrlcgCizTatVkjjAeArpvyknAhfaPrompt() {
  function getTestData() {
    return {}
  }

  const compile = async (opt: { args: { input: string } }) => {
    const GLASS_STATE = {}
    const { input } = opt.args
    const sotu = fs.readFileSync(path.join(__dirname, 'state_of_the_union.txt'), 'utf-8')
    const lines = sotu.split('\n').filter(line => Boolean(line))
    const context = await vectorSearch('sotu', lines, input)

    const GLASSVAR = {}
    const TEMPLATE = `import fs from 'fs'
import path from 'path'
import { vectorSearch } from '../documentQA/vectorSearch'

const sotu = fs.readFileSync(path.join(__dirname, 'state_of_the_union.txt'), 'utf-8')
const lines = sotu.split('\n').filter(line => Boolean(line))
const context = await vectorSearch('sotu', lines, input)

<System>
Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

Here is context you might need to answer the question:
###
${context.join('\n\n')}
###
</System>

<User>
${input}
</User>

<Request model="gpt-3.5-turbo" />`
    return {
      fileName: 'xcMqRRlcgCizTAtVkjjAeARpvyknAHfa.glass',
      model: 'gpt-3.5-turbo',
      interpolatedDoc: TEMPLATE,
      originalDoc:
        "import fs from 'fs'\nimport path from 'path'\nimport { vectorSearch } from '../documentQA/vectorSearch'\n\nconst sotu = fs.readFileSync(path.join(__dirname, 'state_of_the_union.txt'), 'utf-8')\nconst lines = sotu.split('\\n').filter(line => Boolean(line))\nconst context = await vectorSearch('sotu', lines, input)\n\n<System>\nUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\nHere is context you might need to answer the question:\n###\n${context.join('\\n\\n')}\n###\n</System>\n\n<User>\n${input}\n</User>\n\n<Request model=\"gpt-3.5-turbo\" />",
      state: GLASS_STATE,
      interpolationArgs: opt.args || {},
      onResponse: undefined,
    }
  }

  return { getTestData, compile }
}

export const Glass = {
  xcMqRrlcgCizTatVkjjAeArpvyknAhfaGlass: getXcMqRrlcgCizTatVkjjAeArpvyknAhfaPrompt,
}

const { getTestData, compile } = getXcMqRrlcgCizTatVkjjAeArpvyknAhfaPrompt()

;(async function run() {
  const t = getTestData()
  const res: any[] = []
  if (Array.isArray(t)) {
    for (const args of t) {
      const c: any = await compile({ args: { ...args, ...({"input":"hello!"}) } })
      res.push(c)
    }
  } else {
    const c: any = await compile({ args: { ...t, ...({"input":"hello!"}) } })
    res.push(c)
  }
  const ret = await runGlass(res[0], { progress: (data: { nextDoc: string; nextInterpolatedDoc: string; rawResponse?: string }) => {
    console.log('glass-progress: ' + JSON.stringify(data))
  } })
  console.log('glass-result: ' +  JSON.stringify(ret))
})()
